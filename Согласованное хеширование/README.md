# Согласованное хеширование

В последнее время я пару раз сталкивался с последовательным хешированием. 
Документ, в котором была представлена ​​эта идея (`Consistent Hashing and 
Random Trees: Distributed Caching Protocols for Relief of Hot Spots on the 
World Wide Web` by David Karger et al.), появился десять лет назад, хотя в 
последнее время кажется, что эта идея незаметно находит свое применение в 
более и другие сервисы, от Amazon Dynamo до memcached (любезно 
предоставлено Last.fm). Так что же такое последовательное хеширование и 
почему вас это должно волновать?

Потребность в согласованном хешировании возникла из-за ограничений, 
возникающих при работе с наборами кэширующих машин — например, веб-кэшей. 
Если у вас есть набор из n кэш-машин, то общий способ балансировки 
нагрузки между ними состоит в том, чтобы поместить объект o в кэш-машину с 
номером `hash(o)` `mod n`. Это хорошо работает до тех пор, пока вы не 
добавите или не удалите кеш-машины (по какой-либо причине), тогда n 
изменится, и каждый объект хэшируется в новое место. Это может привести к 
катастрофе, поскольку исходные серверы контента перегружены запросами от 
кэш-машин. Как будто кэш внезапно пропал. Что у него есть, в некотором 
смысле. (Вот почему вам следует позаботиться о том, чтобы последовательное 
хеширование не перегружало ваши серверы!)

Было бы неплохо, если бы при добавлении кэш-машины она брала свою 
справедливую долю объектов со всех других кэш-машин. Точно так же, когда 
кэш-машина была удалена, было бы неплохо, если бы ее объекты были 
разделены между оставшимися машинами. Это именно то, что делает 
согласованное хеширование — последовательно отображает объекты на одну и 
ту же машину кэширования, по крайней мере, насколько это возможно. 
Основная идея последовательного алгоритма хеширования состоит в том, чтобы 
хешировать как объекты, так и кэши, используя одну и ту же хеш-функцию. 
Это делается для того, чтобы сопоставить кэш с интервалом, который будет 
содержать некоторое количество хэшей объектов. Если кеш удаляется, то его 
интервал заменяется кешем с соседним интервалом. Все остальные кэши 
остаются без изменений.

# Демонстрация

Давайте рассмотрим это более подробно. Хэш-функция фактически сопоставляет 
объекты и кэши с диапазоном чисел. Это должно быть знакомо каждому 
Java-программисту: метод `hashCode` для `Object ` возвращает `int`, 
лежащее в диапазоне от -231 до 231-1. Представьте, что этот диапазон 
отображается в виде круга, чтобы значения зацикливались. Вот изображение 
круга с рядом объектов (1, 2, 3, 4) и кешей (A, B, C), отмеченных в 
точках, к которым они хэшируются (на основе диаграммы из `Web Caching with 
Consistent Hashing` Дэвида Каргер и др.):


![title](/2007-11-27-image-0000.png)

Чтобы узнать, в какой кэш помещается объект, мы двигаемся по часовой 
стрелке по кругу, пока не найдем точку кэша. Итак, на диаграмме выше мы 
видим, что объекты 1 и 4 принадлежат кешу A, объект 2 принадлежит кешу B, 
а объект 3 принадлежит кешу C. Рассмотрим, что произойдет, если кеш C 
будет удален: объект 3 теперь принадлежит кешу A, и все другие 
сопоставления объектов не изменяются. Если затем добавить еще один кэш D в 
отмеченную позицию, он займет объекты 3 и 4, оставив только объект 1, 
принадлежащий A.

/2007-11-27-image-0001.png

Это работает хорошо, за исключением того, что размер интервалов, 
назначенных каждому кешу, довольно удачен. Поскольку это по существу 
случайно, возможно очень неравномерное распределение объектов между 
кэшами. Решение этой проблемы состоит в том, чтобы представить идею 
«виртуальных узлов», которые являются копиями точек кэша по кругу. Поэтому 
всякий раз, когда мы добавляем кеш, мы создаем для него несколько точек в 
круге. Вы можете увидеть эффект этого на следующем графике, который я 
создал путем моделирования хранения 10 000 объектов в 10 кешах с 
использованием кода, описанного ниже. По оси x указано количество реплик 
точек кэша (в логарифмическом масштабе). Когда он мал, мы видим, что 
распределение объектов по кешам несбалансированное, так как стандартное 
отклонение в процентах от среднего количества объектов в кеше (по оси Y, 
также логарифмическое) велико. По мере увеличения количества реплик 
распределение объектов становится более сбалансированным. Этот эксперимент 
показывает, что цифра в одну или две сотни реплик обеспечивает приемлемый 
баланс (стандартное отклонение, которое составляет примерно от 5% до 10% 
от среднего значения).

/2007-11-27-image-0002.png

 # Реализация
 
Для полноты вот простая реализация на Java. Чтобы последовательное 
хеширование было эффективным, важно иметь хеш-функцию, которая хорошо 
смешивается. Большинство реализаций `hashCode` `Object` плохо смешиваются 
— например, они обычно производят ограниченное количество небольших 
целочисленных значений — поэтому у нас есть интерфейс `HashFunction`, 
позволяющий использовать пользовательскую хеш-функцию. Здесь рекомендуются 
хеши MD5.

```
import java.util.Collection;
import java.util.SortedMap;
import java.util.TreeMap;

public class ConsistentHash<T> {

  private final HashFunction hashFunction;
  private final int numberOfReplicas;
  private final SortedMap<Integer, T> circle =
    new TreeMap<Integer, T>();

  public ConsistentHash(HashFunction hashFunction,
    int numberOfReplicas, Collection<T> nodes) {

    this.hashFunction = hashFunction;
    this.numberOfReplicas = numberOfReplicas;

    for (T node : nodes) {
      add(node);
    }
  }

  public void add(T node) {
    for (int i = 0; i < numberOfReplicas; i++) {
      circle.put(hashFunction.hash(node.toString() + i),
        node);
    }
  }

  public void remove(T node) {
    for (int i = 0; i < numberOfReplicas; i++) {
      circle.remove(hashFunction.hash(node.toString() + i));
    }
  }

  public T get(Object key) {
    if (circle.isEmpty()) {
      return null;
    }
    int hash = hashFunction.hash(key);
    if (!circle.containsKey(hash)) {
      SortedMap<Integer, T> tailMap =
        circle.tailMap(hash);
      hash = tailMap.isEmpty() ?
             circle.firstKey() : tailMap.firstKey();
    }
    return circle.get(hash);
  } 

}
```

Круг представлен в виде отсортированной карты целых чисел, которые 
представляют хэш-значения, в кеши (здесь типа `T`). Когда создается объект 
`ConsistentHash`, каждый узел добавляется в карту круга несколько раз 
(контролируется `numberOfReplicas`). Расположение каждой реплики 
выбирается путем хэширования имени узла вместе с числовым суффиксом, и 
узел сохраняется в каждой из этих точек на карте. 
Чтобы найти узел для объекта (метод `get`), хеш-значение объекта 
используется для поиска на карте. В большинстве случаев в этом 
хеш-значении не будет узла, хранящегося (поскольку пространство 
хеш-значений обычно намного больше, чем количество узлов, даже с 
репликами), поэтому следующий узел находится путем поиска первого ключа в 
хвостовая карта. Если хвостовая карта пуста, то мы обходим круг, получая 
первый ключ в круге.

# Использование

Итак, как вы можете использовать согласованное хеширование? Скорее всего, 
вы встретите его в библиотеке, а не будете кодировать самостоятельно. 
Например, как упоминалось выше, memcached, система кэширования объектов с 
распределенной памятью, теперь имеет клиентов, поддерживающих 
последовательное хеширование. Кетама Last.fm Ричарда Джонса была первой, и 
теперь есть реализация Java Дастином Саллингсом (которая вдохновила мою 
упрощенную демонстрационную реализацию выше). Интересно отметить, что 
алгоритм последовательного хеширования должен быть реализован только на 
клиенте — сервер `memcached` не изменился. Другие системы, использующие 
согласованное хеширование, включают Chord, который представляет собой 
реализацию распределенной хэш-таблицы, и Dynamo от Amazon, который 
представляет собой хранилище ключей и значений (недоступно за пределами 
Amazon).

Автор:
Tom White
tom.e.white@gmail.com
